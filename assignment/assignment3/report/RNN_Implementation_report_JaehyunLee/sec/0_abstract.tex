\begin{abstract}
        In this project, we implemented and compared two recurrent neural network architectures, a vanilla RNN and a GRU, for sequence classification tasks. 
        Both models were trained and evaluated on a sentiment classification dataset. The vanilla RNN achieved a test accuracy of 41.02\%, while the GRU model significantly outperformed it with a test accuracy of 74.25\%. 
        These results demonstrate the superiority of gated recurrent units in capturing long-term dependencies and mitigating the vanishing gradient problem. 
        Our experiments provide insights into the importance of model architecture in recurrent networks and highlight the effectiveness of GRUs for practical sequence modeling tasks.     
\end{abstract}